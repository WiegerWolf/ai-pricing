[
  {
    "model": "gpt4.1",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 1000,
    "hasVision": true,
    "toolUse": true,
    "inputPrice": 2,
    "outputPrice": 8,
    "AAIndex": 47,
    "mcBenchElo": 1204,
    "webdevElo": 1253.30,
    "aiderBench": 52.4,
    "simpleBench": 27,
    "fictionLiveBench": 52.8,
    "modelUrl": "https://openai.com/index/gpt-4-1/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "costAAIndex": 65
  },
  {
    "model": "gpt4.1-mini",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 1000,
    "hasVision": true,
    "toolUse": true,
    "inputPrice": 0.4,
    "outputPrice": 1.6,
    "AAIndex": 42,
    "mcBenchElo": 1029,
    "webdevElo": 1192.68,
    "aiderBench": 32.4,
    "fictionLiveBench": 38.9,
    "modelUrl": "https://openai.com/index/gpt-4-1/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "costAAIndex": 16
  },
  {
    "model": "gpt4.1-nano",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 1000,
    "hasVision": true,
    "toolUse": true,
    "inputPrice": 0.1,
    "outputPrice": 0.4,
    "AAIndex": 30,
    "mcBenchElo": 891,
    "aiderBench": 8.9,
    "fictionLiveBench": 36.1,
    "modelUrl": "https://openai.com/index/gpt-4-1/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "costAAIndex": 3
  },
  {
    "model": "o3",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "modelUrl": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "hasReasoning": true,
    "hasVision": true,
    "toolUse": true,
    "context": 1028,
    "inputPrice": 2,
    "outputPrice": 8,
    "webdevElo": 1186.23,
    "aiderBench": 83.7,
    "AAIndex": 67,
    "simpleBench": 53.1,
    "mcBenchElo": 1213,
    "fictionLiveBench": 83.3,
    "costAAIndex": 390
  },
  {
    "model": "o3-pro",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "modelUrl": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "hasReasoning": true,
    "hasVision": true,
    "toolUse": true,
    "AAIndex": 68,
    "fictionLiveBench": 94.4,
    "context": 1028,
    "aiderBench": 84.9,
    "inputPrice": 20,
    "outputPrice": 80,
    "notes": "o3-pro is available as ‘o3-pro-2025-06-10’ in the Responses API and supports image inputs, function calling, and Structured Outputs. Designed for tough problems, some requests may take several minutes to finish. Try background mode in the Responses API."
  },
  {
    "model": "o4-mini",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "modelUrl": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "hasReasoning": true,
    "hasVision": true,
    "toolUse": true,
    "context": 1028,
    "AAIndex": 65,
    "inputPrice": 1.1,
    "outputPrice": 4.4,
    "aiderBench": 72,
    "simpleBench": 38.7,
    "mcBenchElo": 962,
    "fictionLiveBench": 66.7,
    "costAAIndex": 323,
    "webdevElo": 1118.70
  },
  {
    "model": "o3-mini (high)",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "inputPrice": 1.1,
    "outputPrice": 4.4,
    "simpleBench": 22.8,
    "AAIndex": 55,
    "aiderBench": 60.4,
    "webdevElo": 1136.75,
    "fictionLiveBench": 44.4,
    "toolUse": true,
    "context": 200,
    "modelUrl": "https://platform.openai.com/docs/models#o3-mini",
    "pricingUrl": "https://openai.com/api/pricing/",
    "mcBenchElo": 934,
    "hasReasoning": true,
    "costAAIndex": 345
  },
  {
    "model": "GPT-5",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 400,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "maxOutputTokens": 128,
    "inputPrice": 1.25,
    "outputPrice": 10,
    "simpleBench": 56.7,
    "AAIndex": 69,
    "costAAIndex": 823,
    "aiderBench": 88,
    "fictionLiveBench": 100,
    "webdevElo": 1479.38,
    "modelUrl": "https://openai.com/index/gpt-5-new-era-of-work/",
    "pricingUrl": "https://openai.com/api/pricing/"
  },
  {
    "model": "GPT-5 mini",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 400,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "maxOutputTokens": 128,
    "inputPrice": 0.25,
    "outputPrice": 2.0,
    "AAIndex": 64,
    "costAAIndex": 52,
    "fictionLiveBench": 61.1,
    "modelUrl": "https://openai.com/index/gpt-5-new-era-of-work/",
    "pricingUrl": "https://openai.com/api/pricing/"
  },
  {
    "model": "GPT-5 nano",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 400,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "maxOutputTokens": 128,
    "inputPrice": 0.05,
    "outputPrice": 0.4,
    "AAIndex": 54,
    "costAAIndex": 22,
    "fictionLiveBench": 36.1,
    "modelUrl": "https://openai.com/index/gpt-5-new-era-of-work/",
    "pricingUrl": "https://openai.com/api/pricing/"
  },
  {
    "model": "Claude 4 Opus",
    "provider": "Anthropic",
    "developer": "Anthropic",
    "modelUrl": "https://www.anthropic.com/news/claude-4",
    "pricingUrl": "https://www.anthropic.com/pricing#api",
    "context": 200,
    "inputPrice": 15,
    "outputPrice": 75,
    "AAIndex": 47,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "fictionLiveBench": 55.6,
    "notes": "50% discount with batch processing, prompt caching: write $18.75/MTok, read $1.50/MTok",
    "aiderBench": 72.0,
    "simpleBench": 58.8,
    "mcBenchElo": 1285,
    "webdevElo": 1380.25,
    "costAAIndex": 2036
  },
  {
    "model": "Claude 4 Sonnet",
    "provider": "Anthropic",
    "developer": "Anthropic",
    "modelUrl": "https://www.anthropic.com/news/claude-4",
    "pricingUrl": "https://www.anthropic.com/pricing#api",
    "context": 200,
    "inputPrice": 3,
    "outputPrice": 15,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "AAIndex": 46,
    "fictionLiveBench": 37.5,
    "notes": "50% discount with batch processing, prompt caching: write $3.75/MTok, read $0.30/MTok",
    "aiderBench": 61.3,
    "simpleBench": 45.5,
    "mcBenchElo": 1181,
    "webdevElo": 1359.08,
    "costAAIndex": 342
  },
  {
    "model": "Claude-3-5-Haiku-20241022",
    "provider": "Anthropic",
    "developer": "Anthropic",
    "webdevElo": 1133.41,
    "aiderBench": 28,
    "context": 200,
    "inputPrice": 0.25,
    "outputPrice": 1.25,
    "toolUse": true,
    "AAIndex": 35,
    "notes": "Fastest model, 50% discount available with Batches API",
    "modelUrl": "https://www.anthropic.com/claude/haiku",
    "pricingUrl": "https://www.anthropic.com/pricing#api",
    "mcBenchElo": 811,
    "costAAIndex": 20
  },
  {
    "model": "Gemini-2.5-Pro",
    "provider": "Google AI",
    "developer": "Google AI",
    "simpleBench": 62.4,
    "fictionLiveBench": 83.3,
    "aiderBench": 83.1,
    "webdevElo": 1403.36,
    "AAIndex": 65,
    "inputPrice": 1.25,
    "outputPrice": 10,
    "context": 1048,
    "hasVision": true,
    "toolUse": true,
    "notes": "Pricing is $1.25/$10.00 (input/output) for prompts <= 200k tokens, $2.50/$15.00 for > 200k tokens. Free tier still available.",
    "pricingUrl":"https://ai.google.dev/pricing",
    "modelUrl": "https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/",
    "hasReasoning": true,
    "mcBenchElo": 1425,
    "costAAIndex": 971
  },
  {
    "model": "Gemini 2.0 Flash",
    "provider": "Google AI",
    "developer": "Google AI",
    "fictionLiveBench": 47.2,
    "inputPrice": 0.1,
    "outputPrice": 0.4,
    "context": 1000,
    "aiderBench": 22.2,
    "hasVision": true,
    "AAIndex": 52,
    "simpleBench": 30.7,
    "webdevElo": 1040.29,
    "toolUse": true,
    "modelUrl": "https://ai.google.dev/gemini-api/docs/models/gemini-v2",
    "pricingUrl": "https://ai.google.dev/pricing",
    "mcBenchElo": 1036,
    "costAAIndex": 3
  },
  {
    "model": "Gemini-2.5-Flash-Preview",
    "provider": "Google AI",
    "developer": "Google AI",
    "modelUrl": "https://ai.google.dev/gemini-api/docs/models/gemini-v2",
    "pricingUrl": "https://ai.google.dev/pricing",
    "context": 1000,
    "inputPrice": 0.15,
    "fictionLiveBench": 69.4,
    "mcBenchElo": 1071,
    "AAIndex": 58,
    "outputPrice": 0.6,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "aiderBench": 55.1,
    "notes": "Hybrid reasoning model with 1M token context window and thinking budgets. Output price for 'thinking' mode: $3.50/1M tokens. Context caching: $0.0375/1M tokens (text/image/video). Preview model, pricing and features may change. Free tier available. See pricing page for audio and TTS rates.",
    "webdevElo": 1311.55,
    "costAAIndex": 319
  },
  {
    "model": "Grok-4",
    "provider": "xAI",
    "developer": "xAI",
    "inputPrice": 3,
    "outputPrice": 15,
    "modelUrl": "https://x.ai/news/grok-4",
    "pricingUrl": "https://openrouter.ai/x-ai/grok-4",
    "context": 256,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "fictionLiveBench": 97.2,
    "simpleBench": 60.5,
    "aiderBench": 79.6,
    "AAIndex": 68,
    "costAAIndex": 1630,
    "webdevElo": 1178.16
  },
  {
    "model": "Grok 3 Mini (high)",
    "provider": "OpenRouter",
    "developer": "xAI",
    "inputPrice": 0.3,
    "outputPrice": 0.5,
    "fictionLiveBench": 72.2,
    "AAIndex": 58,
    "aiderBench": 49.3,
    "mcBenchElo": 990,
    "context": 131,
    "pricingUrl": "https://openrouter.ai/x-ai/grok-3-mini-beta",
    "modelUrl": "https://x.ai/blog/grok-3",
    "hasReasoning": true,
    "costAAIndex": 49
  },
  {
    "model": "DeepSeek R1",
    "provider": "DeepSeek",
    "developer": "DeepSeek",
    "context": 64,
    "inputPrice": 0.55,
    "fictionLiveBench": 66.7,
    "aiderBench": 56.9,
    "outputPrice": 2.19,
    "AAIndex": 59,
    "inputPriceCacheHit": 0.014,
    "webdevElo": 1199.38,
    "simpleBench": 40.8,
    "maxOutputTokens": 8,
    "pricingUrl": "https://api-docs.deepseek.com/quick_start/pricing",
    "modelUrl": "https://github.com/deepseek-ai/DeepSeek-R1",
    "mcBenchElo": 1046,
    "hasReasoning": true,
    "costAAIndex": 220
  },
  {
    "model": "DeepSeek-V3-0324",
    "provider": "DeepSeek",
    "developer": "DeepSeek",
    "context": 64,
    "inputPrice": 0.27,
    "toolUse": true,
    "aiderBench": 55.1,
    "AAIndex": 53,
    "outputPrice": 1.1,
    "webdevElo": 1207.95,
    "simpleBench": 27.2,
    "fictionLiveBench": 55.6,
    "mcBenchElo": 1126,
    "pricingUrl": "https://api-docs.deepseek.com/quick_start/pricing/",
    "modelUrl": "https://api-docs.deepseek.com/news/news250325",
    "costAAIndex": 13
  },
  {
    "model": "Llama 3.3 70b instruct",
    "provider": "Groq",
    "developer": "Meta",
    "simpleBench": 19.9,
    "inputPrice": 0.59,
    "outputPrice": 0.79,
    "AAIndex": 31,
    "fictionLiveBench": 33.3,
    "context": 128,
    "toolUse": true,
    "modelUrl": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "pricingUrl": "https://groq.com/pricing/",
    "mcBenchElo": 744,
    "costAAIndex": 8
  },
  {
    "model": "Llama-3.1-405B-Instruct",
    "provider": "OpenRouter",
    "developer": "Meta",
    "context": 128,
    "inputPrice": 2.8,
    "outputPrice": 2.8,
    "webdevElo": 809.51,
    "AAIndex": 29,
    "simpleBench": 23,
    "notes": "Also available for free tier",
    "modelUrl": "https://ai.meta.com/blog/meta-llama-3-1/",
    "pricingUrl": "https://openrouter.ai/meta-llama/llama-3.1-405b-instruct",
    "mcBenchElo": 743,
    "costAAIndex": 41
  },
  {
    "model": "Llama 4 Maverick",
    "provider": "OpenRouter",
    "developer": "Meta",
    "context": 1048,
    "inputPrice": 0.2,
    "outputPrice": 0.6,
    "AAIndex": 42,
    "aiderBench": 15.6,
    "simpleBench": null,
    "fictionLiveBench": 32.0,
    "webdevElo": 1026.93,
    "hasVision": true,
    "toolUse": true,
    "modelUrl": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "pricingUrl": "https://openrouter.ai/meta-llama/llama-4-maverick",
    "costAAIndex": 10
  },
  {
    "model": "Qwen3-235B-A22B-Thinking-2507",
    "provider": "OpenRouter",
    "developer": "Qwen",
    "context": 262,
    "hasReasoning": true,
    "toolUse": true,
    "inputPrice": 0.078,
    "outputPrice": 0.312,
    "maxOutputTokens": 82,
    "webdevElo": 1189.67,
    "modelUrl": "https://qwenlm.github.io/blog/qwen3/",
    "pricingUrl": "https://openrouter.ai/qwen/qwen3-235b-a22b-thinking-2507",
    "notes": "Thinking-only MoE model (22B active) with enforced </think> reasoning blocks, long context (262k) and high token output (up to ~82k)."
  }
]
