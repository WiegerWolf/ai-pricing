[
  {
    "model": "gpt4.1",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 1000,
    "hasVision": true,
    "toolUse": true,
    "inputPrice": 2,
    "outputPrice": 8,
    "mcBenchElo": 1204,
    "webdevElo": 1286,
    "aiderBench": 52.4,
    "simpleBench": 27,
    "fictionLiveBench": 52.8,
    "modelUrl": "https://openai.com/index/gpt-4-1/",
    "pricingUrl": "https://openai.com/api/pricing/"
  },
  {
    "model": "gpt4.1-mini",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 1000,
    "hasVision": true,
    "toolUse": true,
    "inputPrice": 0.4,
    "outputPrice": 1.6,
    "mcBenchElo": 1029,
    "webdevElo": 1186,
    "aiderBench": 32.4,
    "fictionLiveBench": 38.9,
    "modelUrl": "https://openai.com/index/gpt-4-1/",
    "pricingUrl": "https://openai.com/api/pricing/"
  },
  {
    "model": "gpt4.1-nano",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "context": 1000,
    "hasVision": true,
    "toolUse": true,
    "inputPrice": 0.1,
    "outputPrice": 0.4,
    "mcBenchElo": 891,
    "aiderBench": 8.9,
    "fictionLiveBench": 36.1,
    "modelUrl": "https://openai.com/index/gpt-4-1/",
    "pricingUrl": "https://openai.com/api/pricing/"
  },
  {
    "model": "o3",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "modelUrl": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "hasReasoning": true,
    "hasVision": true,
    "toolUse": true,
    "context": 1028,
    "inputPrice": 2,
    "outputPrice": 8,
    "webdevElo": 1188,
    "aiderBench": 83.7,
    "simpleBench": 53.1,
    "mcBenchElo": 1213,
    "fictionLiveBench": 83.3
  },
  {
    "model": "o3-pro",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "modelUrl": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "hasReasoning": true,
    "hasVision": true,
    "toolUse": true,
    "fictionLiveBench": 94.4,
    "context": 1028,
    "inputPrice": 20,
    "outputPrice": 80,
    "notes": "o3-pro is available as ‘o3-pro-2025-06-10’ in the Responses API and supports image inputs, function calling, and Structured Outputs. Designed for tough problems, some requests may take several minutes to finish. Try background mode in the Responses API."
  },
  {
    "model": "o4-mini",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "modelUrl": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "pricingUrl": "https://openai.com/api/pricing/",
    "hasReasoning": true,
    "hasVision": true,
    "toolUse": true,
    "context": 1028,
    "inputPrice": 1.1,
    "outputPrice": 4.4,
    "aiderBench": 72,
    "simpleBench": 38.7,
    "mcBenchElo": 962,
    "fictionLiveBench": 66.7
  },
  {
    "model": "o3-mini (high)",
    "provider": "OpenAI",
    "developer": "OpenAI",
    "inputPrice": 1.1,
    "outputPrice": 4.4,
    "simpleBench": 22.8,
    "aiderBench": 60.4,
    "webdevElo": 1161,
    "fictionLiveBench": 44.4,
    "toolUse": true,
    "context": 200,
    "modelUrl": "https://platform.openai.com/docs/models#o3-mini",
    "pricingUrl": "https://openai.com/api/pricing/",
    "mcBenchElo": 934,
    "hasReasoning": true
  },
  {
    "model": "Claude 4 Opus",
    "provider": "Anthropic",
    "developer": "Anthropic",
    "modelUrl": "https://www.anthropic.com/news/claude-4",
    "pricingUrl": "https://www.anthropic.com/pricing#anthropic-api",
    "context": 200,
    "inputPrice": 15,
    "outputPrice": 75,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "fictionLiveBench": 55.6,
    "notes": "50% discount with batch processing, prompt caching: write $18.75/MTok, read $1.50/MTok",
    "aiderBench": 72.0,
    "simpleBench": 58.8,
    "mcBenchElo": 1285,
    "webdevElo": 1411
  },
  {
    "model": "Claude 4 Sonnet",
    "provider": "Anthropic",
    "developer": "Anthropic",
    "modelUrl": "https://www.anthropic.com/news/claude-4",
    "pricingUrl": "https://www.anthropic.com/pricing#anthropic-api",
    "context": 200,
    "inputPrice": 3,
    "outputPrice": 15,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "fictionLiveBench": 37.5,
    "notes": "50% discount with batch processing, prompt caching: write $3.75/MTok, read $0.30/MTok",
    "aiderBench": 61.3,
    "simpleBench": 45.5,
    "mcBenchElo": 1181,
    "webdevElo": 1389
  },
  {
    "model": "Claude-3-5-Haiku-20241022",
    "provider": "Anthropic",
    "developer": "Anthropic",
    "webdevElo": 1139,
    "aiderBench": 28,
    "context": 200,
    "inputPrice": 0.25,
    "outputPrice": 1.25,
    "toolUse": true,
    "notes": "Fastest model, 50% discount available with Batches API",
    "modelUrl": "https://www.anthropic.com/claude/haiku",
    "pricingUrl": "https://www.anthropic.com/pricing#anthropic-api",
    "mcBenchElo": 811
  },
  {
    "model": "Gemini-2.5-Pro",
    "provider": "Google AI",
    "developer": "Google AI",
    "simpleBench": 62.4,
    "fictionLiveBench": 83.3,
    "aiderBench": 83.1,
    "webdevElo": 1443,
    "inputPrice": 1.25,
    "outputPrice": 10,
    "context": 1048,
    "hasVision": true,
    "toolUse": true,
    "notes": "Pricing is $1.25/$10.00 (input/output) for prompts <= 200k tokens, $2.50/$15.00 for > 200k tokens. Free tier still available.",
    "pricingUrl":"https://ai.google.dev/pricing",
    "modelUrl": "https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/",
    "hasReasoning": true,
    "mcBenchElo": 1425
  },
  {
    "model": "Gemini 2.0 Flash 001",
    "provider": "Google AI",
    "developer": "Google AI",
    "fictionLiveBench": 47.2,
    "inputPrice": 0.1,
    "outputPrice": 0.4,
    "context": 1000,
    "hasVision": true,
    "toolUse": true,
    "modelUrl": "https://ai.google.dev/gemini-api/docs/models/gemini-v2",
    "pricingUrl": "https://ai.google.dev/pricing",
    "mcBenchElo": 1036
  },
  {
    "model": "Gemini-2.5-Flash-Preview",
    "provider": "Google AI",
    "developer": "Google AI",
    "modelUrl": "https://ai.google.dev/gemini-api/docs/models/gemini-v2",
    "pricingUrl": "https://ai.google.dev/pricing",
    "context": 1000,
    "inputPrice": 0.15,
    "fictionLiveBench": 69.4,
    "mcBenchElo": 1071,
    "outputPrice": 0.6,
    "hasVision": true,
    "toolUse": true,
    "hasReasoning": true,
    "aiderBench": 55.1,
    "notes": "Hybrid reasoning model with 1M token context window and thinking budgets. Output price for 'thinking' mode: $3.50/1M tokens. Context caching: $0.0375/1M tokens (text/image/video). Preview model, pricing and features may change. Free tier available. See pricing page for audio and TTS rates.",
    "webdevElo": 1311.55
  },
  {
    "model": "Grok 3 Beta",
    "provider": "OpenRouter",
    "developer": "xAI",
    "webdevElo": 1148,
    "inputPrice": 3,
    "outputPrice": 15,
    "simpleBench": 36.1,
    "fictionLiveBench": 63.9,
    "mcBenchElo": 962,
    "aiderBench": 53.3,
    "hasReasoning": true,
    "toolUse": true,
    "context": 131,
    "pricingUrl": "https://openrouter.ai/x-ai/grok-3-beta",
    "modelUrl": "https://x.ai/blog/grok-3"
  },
  {
    "model": "Grok 3 Mini (high)",
    "provider": "OpenRouter",
    "developer": "xAI",
    "inputPrice": 0.3,
    "outputPrice": 0.5,
    "fictionLiveBench": 72.2,
    "aiderBench": 49.3,
    "mcBenchElo": 990,
    "context": 131,
    "pricingUrl": "https://openrouter.ai/x-ai/grok-3-mini-beta",
    "modelUrl": "https://x.ai/blog/grok-3",
    "hasReasoning": true
  },
  {
    "model": "DeepSeek R1",
    "provider": "DeepSeek",
    "developer": "DeepSeek",
    "context": 64,
    "inputPrice": 0.55,
    "fictionLiveBench": 66.7,
    "aiderBench": 56.9,
    "outputPrice": 2.19,
    "inputPriceCacheHit": 0.014,
    "webdevElo": 1210,
    "simpleBench": 40.8,
    "maxOutputTokens": 8,
    "pricingUrl": "https://api-docs.deepseek.com/quick_start/pricing",
    "modelUrl": "https://github.com/deepseek-ai/DeepSeek-R1",
    "mcBenchElo": 1046,
    "hasReasoning": true
  },
  {
    "model": "DeepSeek-V3-0324",
    "provider": "DeepSeek",
    "developer": "DeepSeek",
    "context": 64,
    "inputPrice": 0.27,
    "toolUse": true,
    "aiderBench": 55.1,
    "outputPrice": 1.1,
    "webdevElo": 1208,
    "simpleBench": 27.2,
    "fictionLiveBench": 55.6,
    "mcBenchElo": 1126,
    "pricingUrl": "https://api-docs.deepseek.com/quick_start/pricing/",
    "modelUrl": "https://api-docs.deepseek.com/news/news250325"
  },
  {
    "model": "Llama 3.3 70b instruct",
    "provider": "Groq",
    "developer": "Meta",
    "simpleBench": 19.9,
    "inputPrice": 0.59,
    "outputPrice": 0.79,
    "fictionLiveBench": 33.3,
    "context": 128,
    "toolUse": true,
    "modelUrl": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "pricingUrl": "https://groq.com/pricing/",
    "mcBenchElo": 744
  },
  {
    "model": "Llama-3.1-405B-Instruct",
    "provider": "OpenRouter",
    "developer": "Meta",
    "context": 128,
    "inputPrice": 2.8,
    "outputPrice": 2.8,
    "webdevElo": 813,
    "simpleBench": 23,
    "notes": "Also available for free tier",
    "modelUrl": "https://ai.meta.com/blog/meta-llama-3-1/",
    "pricingUrl": "https://openrouter.ai/meta-llama/llama-3.1-405b-instruct",
    "mcBenchElo": 743
  },
  {
    "model": "Llama 4 Maverick",
    "provider": "OpenRouter",
    "developer": "Meta",
    "context": 1048,
    "inputPrice": 0.2,
    "outputPrice": 0.6,
    "aiderBench": 15.6,
    "simpleBench": null,
    "fictionLiveBench": 32.0,
    "webdevElo": null,
    "hasVision": true,
    "toolUse": true,
    "modelUrl": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "pricingUrl": "https://openrouter.ai/meta-llama/llama-4-maverick"
  }
]
